{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d762847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb07c1",
   "metadata": {},
   "source": [
    "## Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b03a5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1000/1000 [00:05<00:00, 190.12ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "265553291"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_dataset_config_names('Helsinki-NLP/opus-100')\n",
    "data = load_dataset('Helsinki-NLP/opus-100', 'bn-en')\n",
    "data['train'].to_csv(\"./data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f100c",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "06580d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/arafat/projects/deeplearning_crash_course/data/train_data.csv')\n",
    "df['translation_dict'] = df['translation'].apply(eval)\n",
    "\n",
    "\n",
    "df['bn'] = df['translation_dict'].apply(lambda x: x['bn'])\n",
    "df['en'] = df['translation_dict'].apply(lambda x: x['en'])\n",
    "\n",
    "\n",
    "df = df.drop('translation_dict', axis=1)\n",
    "df.to_csv(\"./data/bangla_english_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b4ae6742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আবশ্যক',\n",
       "       'কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান করি , তা তাদের পক ্ ষে কল ্ যাণকর । আমি তো তাদেরকে অবকাশ দেই যাতে করে তারা পাপে উন ্ নতি লাভ করতে পারে । বস ্ তুতঃ তাদের জন ্ য রয়েছে লাঞ ্ ছনাজনক শাস ্ তি ।',\n",
       "       'সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসবে না এবং তারা সাহায ্ যপ ্ রাপ ্ তও হবে না ।',\n",
       "       'একটা দুঃসংবাদ দিবো।',\n",
       "       \"আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লাহ্\\u200cর সন্তান ও তাঁর প্রিয়পাত্র।’’ তুমি বলো -- ''তবে কেন তোমাদের অপরাধের জন্য তিনি তোমাদের শাস্তি দেন? না, যাদের তিনি সৃষ্টি করেছেন তোমরা তাদের মধ্যেকার মানুষ। তিনি যাকে ইচ্ছে করেন পরিত্রাণ করেন এবং যাকে ইচ্ছে করেন শাস্তি দেন।’’ আর আল্লাহ্\\u200cরই মহাকাশমন্ডল ও পৃথিবীর সাম্রাজ্য এবং এই দুইয়ের মধ্যে যা আছে, আর তাঁরই দিকে প্রত্যাবর্তন।\",\n",
       "       'এটা দেখ তো।',\n",
       "       'এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা দিয়েছি । তাদের মধ ্ যে কেউ তো হলো তারা যার সাথে আল ্ লাহ কথা বলেছেন , আর কারও মর ্ যাদা উচ ্ চতর করেছেন এবং আমি মরিয়ম তনয় ঈসাকে প ্ রকৃষ ্ ট মু ’ জেযা দান করেছি এবং তাকে শক ্ তি দান করেছি ‘ রুহূল কুদ ্ দুস ’ অর ্ থৎ জিবরাঈলের মাধ ্ যমে । আর আল ্ লাহ যদি ইচ ্ ছা করতেন , তাহলে পরিস ্ কার নির ্ দেশ এসে যাবার পর পয়গম ্ বরদের পেছনে যারা ছিল তারা লড়াই করতো না । কিন ্ তু তাদের মধ ্ যে মতবিরোধ সৃষ ্ টি হয়ে গেছে । অতঃপর তাদের কেউ তো ঈমান এনেছে , আর কেউ হয়েছে কাফের । আর আল ্ লাহ যদি ইচ ্ ছা করতেন , তাহলে তারা পরস ্ পর লড়াই করতো , কিন ্ তু আল ্ লাহ তাই করেন , যা তিনি ইচ ্ ছা করেন ।',\n",
       "       'দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো দিবারাত ্ রি চক ্ রান ্ ত করে আমাদেরকে নির ্ দেশ দিতে যেন আমরা আল ্ লাহকে না মানি এবং তাঁর অংশীদার সাব ্ যস ্ ত করি তারা যখন শাস ্ তি দেখবে , তখন মনের অনুতাপ মনেই রাখবে । বস ্ তুতঃ আমি কাফেরদের গলায় বেড়ী পরাব । তারা সে প ্ রতিফলই পেয়ে থাকে যা তারা করত ।',\n",
       "       'রুহিতনের বিবি', 'এখন বাইরে চলো, চলো, যাই', 'যথেষ্ট হয়েছে.',\n",
       "       'এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কিছু আছে তা নিশ ্ চয়ই আল ্ লাহ ্ \\u200c র ? তিনি অবশ ্ য জানেন তোমরা যা-কিছুতে রয়েছ । আর যেদিন তাদের তাঁর কাছে ফেরত নেওয়া হবে সেদিন তাদের জানিয়ে দেওয়া হবে যা তারা করত । আর আল ্ লাহ ্ সব- কিছু সন ্ বন ্ ধে সর ্ বজ ্ ঞাতা ।',\n",
       "       'শুভ রাত্রি, জনাব ।',\n",
       "       'তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হয়ে গেছে ।',\n",
       "       'সিরিলিক/ইউক্রেনীয়', 'KDE বিভাজন ব্যবস্থাপক', 'সবচেয়ে ভাল',\n",
       "       'আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জলভাষী । অতএব , তাকে আমার সাথে সাহায ্ যের জন ্ যে প ্ রেরণ করুন । সে আমাকে সমর ্ থন জানাবে । আমি আশংকা করি যে , তারা আমাকে মিথ ্ যাবাদী বলবে ।',\n",
       "       'না !', 'ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ',\n",
       "       '%s: groupid মান %d করা যায়নি', 'ঘন্টা',\n",
       "       'কাফেররা কি এখন অপেক ্ ষা করছে যে , তাদের কাছে ফেরেশতারা আসবে কিংবা আপনার পালনকর ্ তার নির ্ দেশ পৌছবে ? তাদের পূর ্ ববর ্ তীরা এমনই করেছিল । আল ্ লাহ তাদের প ্ রতি অবিচার করেননি ; কিন ্ তু তারা স ্ বয়ং নিজেদের প ্ রতি জুলুম করেছিল ।',\n",
       "       'আমার... ...স্বামী.',\n",
       "       'আপনার ওয়েবক্যামে ছবি এবং ভিডিও নিন, আনন্দিত গ্রাফিকেল আবহ সহযোগে',\n",
       "       'MD5 ফিঙ্গারপ্রিন্ট', 'ডিস্ক অনুলিপি (_c)', 'আপনি একা?',\n",
       "       'আর তোমরা নিশ ্ চয়ই আমাদের কাছে এসেছ একে একে যেমন তোমাদের আমরা প ্ রথমবার সৃষ ্ টি করেছিলাম , আর যা তোমাদের দিয়েছিলাম তা তোমরা তোমাদের পিঠের পেছনে ফেলে এসেছ , আর তোমাদের সঙ ্ গে তোমাদের সুপারিশকারীদের দেখছি না যাদের তোমরা দাবি করতে যে তারা তোমাদের মধ ্ যে নিশ ্ চিত অংশীদার । নিশ ্ চয় তোমাদের মধ ্ যেকার বন ্ ধন ছিন ্ ন হয়েছে আর তোমাদের থেকে উধাও হয়েছে যা তোমরা দাবি করতে ।',\n",
       "       'রহমান , রহীম ।', 'এটা আমার প্যান ছিলনা\\u200e.',\n",
       "       'ক্লায়েন্ট সংক্রান্ত অপশন প্রদর্শন করা হবে',\n",
       "       'আমি সফল হতে পারার আগেই আমাকে ওরা ধরে নিয়ে গেল', '-আপনি কে?',\n",
       "       'PKCS #1 MD2 RSA এনক্রিপশনসহ',\n",
       "       'হাই পয়েন্টCity name (optional, probably does not need a translation)',\n",
       "       'প্রাপকদের তথ্য ব্যবহার করে অনুসন্ধান ফোল্ডার নির্মাণ করুন...(_t)',\n",
       "       'কিন ্ ত তাদের তো এদের উপরে তত ্ ত ্ বাবধায়ক করে পাঠানো হয় নি ।',\n",
       "       'প্রতিবার Evolution আরম্ভ করার সময় পরীক্ষা করা হবে এটি ডিফল্ট মেইলার হিসাবে চিহ্নিত কিনা।',\n",
       "       'l', 'বুধবার', 'অ্যারিজোনা.',\n",
       "       '%s: %s সিগন্যাল হ্যান্ডলার স্থাপনে সমস্যা হয়েছে: %s',\n",
       "       'না, না, না.',\n",
       "       'আপনি কি এই অ্যাকাউন্ট ও এর সাথে যুক্ত সমস্ত প্রক্সি মুছে ফেলতে চান?',\n",
       "       'যাতে তোমরা তাদের পিঠের উপর আরোহণ কর । অতঃপর তোমাদের পালনকর ্ তার নেয়ামত স ্ মরণ কর এবং বল পবিত ্ র তিনি , যিনি এদেরকে আমাদের বশীভূত করে দিয়েছেন এবং আমরা এদেরকে বশীভূত করতে সক ্ ষম ছিলাম না ।',\n",
       "       'আবার... ...', 'চিড়িতনের টেক্কা',\n",
       "       \"লোকেরা কি মনে করে যে তাদের ছেড়ে দেওয়া হবে যদি তারা বলে -- ''আমরা ঈমান এনেছি’’, আর তাদের পরীক্ষা করা হবে না?\",\n",
       "       'চিন্তা কোরনা.', 'কেন তুমি তোমার মন পাল্টালে?'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100:150, ['bn', 'en']].values[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b3bb6",
   "metadata": {},
   "source": [
    "## Train a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "203c3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7cb1f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_tokenizer(file_path:str, output_path:str, vocab_size:int, lang:str = Literal['bn', 'en']):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\"File Path Does Not Exist\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna()\n",
    "    training_data = df.loc[:, lang].values\n",
    "    \n",
    "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(vocab_size=vocab_size,\n",
    "                               min_frequency=2,\n",
    "                               special_tokens=[\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
    "    \n",
    "    tokenizer.train_from_iterator(training_data, trainer)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    tokenizer.save(f\"./{output_path}/{lang}_tokenizer.json\")\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "626e5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/arafat/projects/deeplearning_crash_course/data/bangla_english_translation.csv'\n",
    "en_tokenizer = train_and_save_tokenizer(path, 'Tokenizer', 1000, 'en')\n",
    "bn_tokenizer = train_and_save_tokenizer(path, 'Tokenizer', 1000, 'bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3eecad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([90, 15, 12, 0, 0, 1, 1, 1, 1, 1], [90, 15, 218, 0, 5, 98, 7, 0, 15, 278])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_file('/home/arafat/projects/deeplearning_crash_course/Tokenizer/en_tokenizer.json')\n",
    "tokenizer.enable_padding(\n",
    "    pad_id=tokenizer.token_to_id(\"[PAD]\"),\n",
    "    pad_token=\"[PAD]\",\n",
    "    length=None,\n",
    "    # length=50,\n",
    "    direction='right'\n",
    ")\n",
    "\n",
    "sample_text = [\"This is a test sentence\", \"This is another sentence. But the sentence is long\"]\n",
    "encoding = tokenizer.encode_batch(sample_text)\n",
    "encoding[0].ids, encoding[1].ids\n",
    "\n",
    "# token = torch.stack([encoding[0].ids, encoding[1].ids], padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea990a1a",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a225708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineTranslation(Dataset):\n",
    "    def __init__(self, file_path:str, en_tokenizer_path:str, bn_tokenizer_path:str):\n",
    "        super().__init__()\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {file_path}\")\n",
    "        if not os.path.exists(en_tokenizer_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {en_tokenizer_path}\")\n",
    "        if not os.path.exists(bn_tokenizer_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {bn_tokenizer_path}\")\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.en_tokenizer = Tokenizer.from_file(en_tokenizer_path)\n",
    "        self.bn_tokenizer = Tokenizer.from_file(bn_tokenizer_path)\n",
    "        \n",
    "        self.en_tokenizer.enable_padding(\n",
    "            pad_id=self.en_tokenizer.token_to_id(\"[PAD]\"),\n",
    "            pad_token=\"[PAD]\",\n",
    "            length=None,\n",
    "            direction='right'\n",
    "        )\n",
    "        \n",
    "        self.bn_tokenizer.enable_padding(\n",
    "            pad_id=self.bn_tokenizer.token_to_id(\"[PAD]\"),\n",
    "            pad_token=\"[PAD]\",\n",
    "            length=None,\n",
    "            direction='right'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        csv_file = pd.read_csv(self.file_path)\n",
    "        sentences = csv_file.loc[idx, ['bn', 'en']].values\n",
    "        bangla, english = sentences[:, 0], sentences[:, 1]\n",
    "        bn_token_id = self.bn_tokenizer.encode(bangla).ids\n",
    "        en_token_id = self.en_tokenizer.encode(english).ids\n",
    "        return bangla, english\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c93e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
