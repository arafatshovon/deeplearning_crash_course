{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d762847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arafat/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb07c1",
   "metadata": {},
   "source": [
    "## Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b03a5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1000/1000 [00:05<00:00, 187.98ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "265553291"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_dataset_config_names('Helsinki-NLP/opus-100')\n",
    "data = load_dataset('Helsinki-NLP/opus-100', 'bn-en')\n",
    "data['train'].to_csv(\"./data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f100c",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "06580d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/arafat/projects/deeplearning_crash_course/data/train_data.csv')\n",
    "df['translation_dict'] = df['translation'].apply(eval)\n",
    "\n",
    "\n",
    "df['bn'] = df['translation_dict'].apply(lambda x: x['bn'])\n",
    "df['en'] = df['translation_dict'].apply(lambda x: x['en'])\n",
    "\n",
    "\n",
    "df = df.drop('translation_dict', axis=1)\n",
    "df.to_csv(\"./data/bangla_english_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b4ae6742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আবশ্যক',\n",
       "       'কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান করি , তা তাদের পক ্ ষে কল ্ যাণকর । আমি তো তাদেরকে অবকাশ দেই যাতে করে তারা পাপে উন ্ নতি লাভ করতে পারে । বস ্ তুতঃ তাদের জন ্ য রয়েছে লাঞ ্ ছনাজনক শাস ্ তি ।',\n",
       "       'সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসবে না এবং তারা সাহায ্ যপ ্ রাপ ্ তও হবে না ।',\n",
       "       'একটা দুঃসংবাদ দিবো।',\n",
       "       \"আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লাহ্\\u200cর সন্তান ও তাঁর প্রিয়পাত্র।’’ তুমি বলো -- ''তবে কেন তোমাদের অপরাধের জন্য তিনি তোমাদের শাস্তি দেন? না, যাদের তিনি সৃষ্টি করেছেন তোমরা তাদের মধ্যেকার মানুষ। তিনি যাকে ইচ্ছে করেন পরিত্রাণ করেন এবং যাকে ইচ্ছে করেন শাস্তি দেন।’’ আর আল্লাহ্\\u200cরই মহাকাশমন্ডল ও পৃথিবীর সাম্রাজ্য এবং এই দুইয়ের মধ্যে যা আছে, আর তাঁরই দিকে প্রত্যাবর্তন।\",\n",
       "       'এটা দেখ তো।',\n",
       "       'এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা দিয়েছি । তাদের মধ ্ যে কেউ তো হলো তারা যার সাথে আল ্ লাহ কথা বলেছেন , আর কারও মর ্ যাদা উচ ্ চতর করেছেন এবং আমি মরিয়ম তনয় ঈসাকে প ্ রকৃষ ্ ট মু ’ জেযা দান করেছি এবং তাকে শক ্ তি দান করেছি ‘ রুহূল কুদ ্ দুস ’ অর ্ থৎ জিবরাঈলের মাধ ্ যমে । আর আল ্ লাহ যদি ইচ ্ ছা করতেন , তাহলে পরিস ্ কার নির ্ দেশ এসে যাবার পর পয়গম ্ বরদের পেছনে যারা ছিল তারা লড়াই করতো না । কিন ্ তু তাদের মধ ্ যে মতবিরোধ সৃষ ্ টি হয়ে গেছে । অতঃপর তাদের কেউ তো ঈমান এনেছে , আর কেউ হয়েছে কাফের । আর আল ্ লাহ যদি ইচ ্ ছা করতেন , তাহলে তারা পরস ্ পর লড়াই করতো , কিন ্ তু আল ্ লাহ তাই করেন , যা তিনি ইচ ্ ছা করেন ।',\n",
       "       'দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো দিবারাত ্ রি চক ্ রান ্ ত করে আমাদেরকে নির ্ দেশ দিতে যেন আমরা আল ্ লাহকে না মানি এবং তাঁর অংশীদার সাব ্ যস ্ ত করি তারা যখন শাস ্ তি দেখবে , তখন মনের অনুতাপ মনেই রাখবে । বস ্ তুতঃ আমি কাফেরদের গলায় বেড়ী পরাব । তারা সে প ্ রতিফলই পেয়ে থাকে যা তারা করত ।',\n",
       "       'রুহিতনের বিবি', 'এখন বাইরে চলো, চলো, যাই', 'যথেষ্ট হয়েছে.',\n",
       "       'এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কিছু আছে তা নিশ ্ চয়ই আল ্ লাহ ্ \\u200c র ? তিনি অবশ ্ য জানেন তোমরা যা-কিছুতে রয়েছ । আর যেদিন তাদের তাঁর কাছে ফেরত নেওয়া হবে সেদিন তাদের জানিয়ে দেওয়া হবে যা তারা করত । আর আল ্ লাহ ্ সব- কিছু সন ্ বন ্ ধে সর ্ বজ ্ ঞাতা ।',\n",
       "       'শুভ রাত্রি, জনাব ।',\n",
       "       'তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হয়ে গেছে ।',\n",
       "       'সিরিলিক/ইউক্রেনীয়', 'KDE বিভাজন ব্যবস্থাপক', 'সবচেয়ে ভাল',\n",
       "       'আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জলভাষী । অতএব , তাকে আমার সাথে সাহায ্ যের জন ্ যে প ্ রেরণ করুন । সে আমাকে সমর ্ থন জানাবে । আমি আশংকা করি যে , তারা আমাকে মিথ ্ যাবাদী বলবে ।',\n",
       "       'না !', 'ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ',\n",
       "       '%s: groupid মান %d করা যায়নি', 'ঘন্টা',\n",
       "       'কাফেররা কি এখন অপেক ্ ষা করছে যে , তাদের কাছে ফেরেশতারা আসবে কিংবা আপনার পালনকর ্ তার নির ্ দেশ পৌছবে ? তাদের পূর ্ ববর ্ তীরা এমনই করেছিল । আল ্ লাহ তাদের প ্ রতি অবিচার করেননি ; কিন ্ তু তারা স ্ বয়ং নিজেদের প ্ রতি জুলুম করেছিল ।',\n",
       "       'আমার... ...স্বামী.',\n",
       "       'আপনার ওয়েবক্যামে ছবি এবং ভিডিও নিন, আনন্দিত গ্রাফিকেল আবহ সহযোগে',\n",
       "       'MD5 ফিঙ্গারপ্রিন্ট', 'ডিস্ক অনুলিপি (_c)', 'আপনি একা?',\n",
       "       'আর তোমরা নিশ ্ চয়ই আমাদের কাছে এসেছ একে একে যেমন তোমাদের আমরা প ্ রথমবার সৃষ ্ টি করেছিলাম , আর যা তোমাদের দিয়েছিলাম তা তোমরা তোমাদের পিঠের পেছনে ফেলে এসেছ , আর তোমাদের সঙ ্ গে তোমাদের সুপারিশকারীদের দেখছি না যাদের তোমরা দাবি করতে যে তারা তোমাদের মধ ্ যে নিশ ্ চিত অংশীদার । নিশ ্ চয় তোমাদের মধ ্ যেকার বন ্ ধন ছিন ্ ন হয়েছে আর তোমাদের থেকে উধাও হয়েছে যা তোমরা দাবি করতে ।',\n",
       "       'রহমান , রহীম ।', 'এটা আমার প্যান ছিলনা\\u200e.',\n",
       "       'ক্লায়েন্ট সংক্রান্ত অপশন প্রদর্শন করা হবে',\n",
       "       'আমি সফল হতে পারার আগেই আমাকে ওরা ধরে নিয়ে গেল', '-আপনি কে?',\n",
       "       'PKCS #1 MD2 RSA এনক্রিপশনসহ',\n",
       "       'হাই পয়েন্টCity name (optional, probably does not need a translation)',\n",
       "       'প্রাপকদের তথ্য ব্যবহার করে অনুসন্ধান ফোল্ডার নির্মাণ করুন...(_t)',\n",
       "       'কিন ্ ত তাদের তো এদের উপরে তত ্ ত ্ বাবধায়ক করে পাঠানো হয় নি ।',\n",
       "       'প্রতিবার Evolution আরম্ভ করার সময় পরীক্ষা করা হবে এটি ডিফল্ট মেইলার হিসাবে চিহ্নিত কিনা।',\n",
       "       'l', 'বুধবার', 'অ্যারিজোনা.',\n",
       "       '%s: %s সিগন্যাল হ্যান্ডলার স্থাপনে সমস্যা হয়েছে: %s',\n",
       "       'না, না, না.',\n",
       "       'আপনি কি এই অ্যাকাউন্ট ও এর সাথে যুক্ত সমস্ত প্রক্সি মুছে ফেলতে চান?',\n",
       "       'যাতে তোমরা তাদের পিঠের উপর আরোহণ কর । অতঃপর তোমাদের পালনকর ্ তার নেয়ামত স ্ মরণ কর এবং বল পবিত ্ র তিনি , যিনি এদেরকে আমাদের বশীভূত করে দিয়েছেন এবং আমরা এদেরকে বশীভূত করতে সক ্ ষম ছিলাম না ।',\n",
       "       'আবার... ...', 'চিড়িতনের টেক্কা',\n",
       "       \"লোকেরা কি মনে করে যে তাদের ছেড়ে দেওয়া হবে যদি তারা বলে -- ''আমরা ঈমান এনেছি’’, আর তাদের পরীক্ষা করা হবে না?\",\n",
       "       'চিন্তা কোরনা.', 'কেন তুমি তোমার মন পাল্টালে?'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100:150, ['bn', 'en']].values[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b3bb6",
   "metadata": {},
   "source": [
    "## Train a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203c3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb1f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_tokenizer(file_path:str, output_path:str, vocab_size:int, lang:str = Literal['bn', 'en']):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\"File Path Does Not Exist\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna()\n",
    "    training_data = df.loc[:, lang].values\n",
    "    \n",
    "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(vocab_size=vocab_size,\n",
    "                               min_frequency=2,\n",
    "                               special_tokens=[\"[UNK]\", \"[PAD]\", \"[EOS]\", \"[SOS]\"])\n",
    "    \n",
    "    tokenizer.train_from_iterator(training_data, trainer)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    tokenizer.save(f\"./{output_path}/{lang}_tokenizer.json\")\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626e5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/arafat/projects/deeplearning_crash_course/data/bangla_english_translation.csv'\n",
    "en_tokenizer = train_and_save_tokenizer(path, 'Tokenizer', 1000, 'en')\n",
    "bn_tokenizer = train_and_save_tokenizer(path, 'Tokenizer', 1000, 'bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eecad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([89, 14, 11, 0, 0], ['This', 'is', 'a', '[UNK]', '[UNK]'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_file('/home/arafat/projects/deeplearning_crash_course/Tokenizer/en_tokenizer.json')\n",
    "tokenizer.enable_padding(\n",
    "    pad_id=tokenizer.token_to_id(\"[PAD]\"),\n",
    "    pad_token=\"[PAD]\",\n",
    "    length=None,\n",
    "    # length=50,\n",
    "    direction='right'\n",
    ")\n",
    "\n",
    "sample_text = \"This is a test sentence\"\n",
    "encoding = tokenizer.encode(sample_text)\n",
    "encoding.ids, encoding.tokens\n",
    "\n",
    "# token = torch.stack([encoding[0].ids, encoding[1].ids], padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea990a1a",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a225708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2643fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(batch):\n",
    "    bn_sentences = [item[0] for item in batch]\n",
    "    en_sentences = [item[1] for item in batch]\n",
    "    bn_padded = torch.nn.utils.rnn.pad_sequence(bn_sentences, batch_first=True, padding_value=1)\n",
    "    en_padded = torch.nn.utils.rnn.pad_sequence(en_sentences, batch_first=True, padding_value=1)\n",
    "    return bn_padded, en_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineTranslation(Dataset):\n",
    "    def __init__(self, file_path:str, en_tokenizer_path:str, bn_tokenizer_path:str, split:str='train'):\n",
    "        super().__init__()\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {file_path}\")\n",
    "        if not os.path.exists(en_tokenizer_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {en_tokenizer_path}\")\n",
    "        if not os.path.exists(bn_tokenizer_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {bn_tokenizer_path}\")\n",
    "        assert split in [\"train\", \"validation\"], \"Split must be either 'train' or 'validation'\"\n",
    "                \n",
    "        self.file_path = file_path\n",
    "        self.csv_file = pd.read_csv(file_path)\n",
    "        if split == \"train\":\n",
    "            self.csv_file = self.csv_file.sample(frac=0.8, random_state=42)\n",
    "            \n",
    "        self.en_tokenizer = Tokenizer.from_file(en_tokenizer_path)\n",
    "        self.bn_tokenizer = Tokenizer.from_file(bn_tokenizer_path)\n",
    "        \n",
    "        self.en_tokenizer.enable_padding(\n",
    "            pad_id=self.en_tokenizer.token_to_id(\"[PAD]\"),\n",
    "            pad_token=\"[PAD]\",\n",
    "            length=None,\n",
    "            direction='right'\n",
    "        )\n",
    "        \n",
    "        self.bn_tokenizer.enable_padding(\n",
    "            pad_id=self.bn_tokenizer.token_to_id(\"[PAD]\"),\n",
    "            pad_token=\"[PAD]\",\n",
    "            length=None,\n",
    "            direction='right'\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.csv_file.loc[idx, ['bn', 'en']].values\n",
    "        bangla, english = sentences[0], sentences[1]\n",
    "        bn_encoding = self.bn_tokenizer.encode(bangla)\n",
    "        en_encoding = self.en_tokenizer.encode(english)\n",
    "        return torch.tensor(bn_encoding.ids), torch.tensor(en_encoding.ids)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b9c93e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MachineTranslation(path, './Tokenizer/en_tokenizer.json', './Tokenizer/bn_tokenizer.json')\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ddfd6c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 57]), torch.Size([10, 67]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fa68ff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ছবি জন্য তৈরি করা'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = x[9].tolist()\n",
    "bn_tokenizer.decode(token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "02e4be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bn    হ্যাঁ?\n",
       "en     Yeah?\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/arafat/projects/deeplearning_crash_course/data/bangla_english_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b4fad01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আ...</td>\n",
       "      <td>You must name this Search Folder.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান ক...</td>\n",
       "      <td>Those who disbelieve should not assume that We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসব...</td>\n",
       "      <td>A day on which their scheming will not benefit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>একটা দুঃসংবাদ দিবো।</td>\n",
       "      <td>I've got some bad news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লা...</td>\n",
       "      <td>No : You are only mortals , of His creation . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>এটা দেখ তো।</td>\n",
       "      <td>Check that out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা ...</td>\n",
       "      <td>And to Jesus , son of Mary , We gave tokens , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো...</td>\n",
       "      <td>Those who were despised say unto those who wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>রুহিতনের বিবি</td>\n",
       "      <td>the queen of diamonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>এখন বাইরে চলো, চলো, যাই</td>\n",
       "      <td>Come on, let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>যথেষ্ট হয়েছে.</td>\n",
       "      <td>That's enough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কি...</td>\n",
       "      <td>He has Knowledge of what state you are upon . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>শুভ রাত্রি, জনাব ।</td>\n",
       "      <td>Good night, sir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হ...</td>\n",
       "      <td>Then go to the Pharaoh as he has become exceed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>সিরিলিক/ইউক্রেনীয়</td>\n",
       "      <td>Cyrillic/Ukrainian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KDE বিভাজন ব্যবস্থাপক</td>\n",
       "      <td>KDE Partition Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>সবচেয়ে ভাল</td>\n",
       "      <td>The best.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জল...</td>\n",
       "      <td>And my brother , Haroun , he is more eloquent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>না !</td>\n",
       "      <td>No!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ</td>\n",
       "      <td>3D artillery game similar to Scorched Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>%s: groupid মান %d করা যায়নি</td>\n",
       "      <td>%s: Couldn't set groupid to %d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    bn  \\\n",
       "100  চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আ...   \n",
       "101  কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান ক...   \n",
       "102  সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসব...   \n",
       "103                                একটা দুঃসংবাদ দিবো।   \n",
       "104  আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লা...   \n",
       "105                                        এটা দেখ তো।   \n",
       "106  এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা ...   \n",
       "107  দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো...   \n",
       "108                                      রুহিতনের বিবি   \n",
       "109                            এখন বাইরে চলো, চলো, যাই   \n",
       "110                                      যথেষ্ট হয়েছে.   \n",
       "111  এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কি...   \n",
       "112                                 শুভ রাত্রি, জনাব ।   \n",
       "113  তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হ...   \n",
       "114                                  সিরিলিক/ইউক্রেনীয়   \n",
       "115                              KDE বিভাজন ব্যবস্থাপক   \n",
       "116                                         সবচেয়ে ভাল   \n",
       "117  আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জল...   \n",
       "118                                               না !   \n",
       "119      ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ   \n",
       "120                       %s: groupid মান %d করা যায়নি   \n",
       "\n",
       "                                                    en  \n",
       "100                  You must name this Search Folder.  \n",
       "101  Those who disbelieve should not assume that We...  \n",
       "102  A day on which their scheming will not benefit...  \n",
       "103                            I've got some bad news.  \n",
       "104  No : You are only mortals , of His creation . ...  \n",
       "105                                    Check that out.  \n",
       "106  And to Jesus , son of Mary , We gave tokens , ...  \n",
       "107  Those who were despised say unto those who wer...  \n",
       "108                              the queen of diamonds  \n",
       "109                                 Come on, let's go.  \n",
       "110                                     That's enough.  \n",
       "111  He has Knowledge of what state you are upon . ...  \n",
       "112                                   Good night, sir.  \n",
       "113  Then go to the Pharaoh as he has become exceed...  \n",
       "114                                 Cyrillic/Ukrainian  \n",
       "115                              KDE Partition Manager  \n",
       "116                                          The best.  \n",
       "117  And my brother , Haroun , he is more eloquent ...  \n",
       "118                                                No!  \n",
       "119        3D artillery game similar to Scorched Earth  \n",
       "120                     %s: Couldn't set groupid to %d  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100:120, ['bn', 'en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a006a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4, 10,  2,  3,  4,  5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,10])\n",
    "y = torch.tensor([2,3,4,5])\n",
    "torch.cat([x, y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969c321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820177f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.zeros(10, 10)\n",
    "mask[:x.shape[0], :x.shape[1]] = 1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f1834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7036, 0.4407, 0.7141, 0.2086, 0.4266],\n",
       "        [0.8826, 0.2820, 0.4906, 0.6313, 0.6343],\n",
       "        [0.2236, 0.9251, 0.9680, 0.4137, 0.7161],\n",
       "        [0.2739, 0.2671, 0.5580, 0.2215, 0.4544],\n",
       "        [0.6278, 0.4673, 0.2455, 0.0232, 0.7803]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d9c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:/notebook/deeplearning_crash_course/data/bangla_english_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8561988c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sample = data.sample(frac=\u001b[32m0.3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m other = data[\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\notebook\\deeplearning_crash_course\\dl_env\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\notebook\\deeplearning_crash_course\\dl_env\\Lib\\site-packages\\pandas\\core\\arraylike.py:44\u001b[39m, in \u001b[36mOpsMixin.__ne__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__ne__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mne\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\notebook\\deeplearning_crash_course\\dl_env\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:1070\u001b[39m, in \u001b[36mRangeIndex._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, RangeIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._range == other._range:\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Both are immutable so if ._range attr. are equal, shortcut is possible\u001b[39;00m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._cmp_method(\u001b[38;5;28mself\u001b[39m, op)\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\notebook\\deeplearning_crash_course\\dl_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7251\u001b[39m, in \u001b[36mIndex._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   7246\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[32m   7248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, (np.ndarray, Index, ABCSeries, ExtensionArray)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[32m   7249\u001b[39m     \u001b[38;5;28mself\u001b[39m\n\u001b[32m   7250\u001b[39m ) != \u001b[38;5;28mlen\u001b[39m(other):\n\u001b[32m-> \u001b[39m\u001b[32m7251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLengths must match to compare\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCMultiIndex):\n\u001b[32m   7254\u001b[39m     other = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "sample = data.sample(frac=0.3)\n",
    "other = data[data.index != sample.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2973ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
