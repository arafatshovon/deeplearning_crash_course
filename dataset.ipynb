{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d762847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arafat/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb07c1",
   "metadata": {},
   "source": [
    "## Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b03a5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1000/1000 [00:05<00:00, 187.98ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "265553291"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_dataset_config_names('Helsinki-NLP/opus-100')\n",
    "data = load_dataset('Helsinki-NLP/opus-100', 'bn-en')\n",
    "data['train'].to_csv(\"./data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f100c",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "06580d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/arafat/projects/deeplearning_crash_course/data/train_data.csv')\n",
    "df['translation_dict'] = df['translation'].apply(eval)\n",
    "\n",
    "\n",
    "df['bn'] = df['translation_dict'].apply(lambda x: x['bn'])\n",
    "df['en'] = df['translation_dict'].apply(lambda x: x['en'])\n",
    "\n",
    "\n",
    "df = df.drop('translation_dict', axis=1)\n",
    "df.to_csv(\"./data/bangla_english_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b4ae6742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আবশ্যক',\n",
       "       'কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান করি , তা তাদের পক ্ ষে কল ্ যাণকর । আমি তো তাদেরকে অবকাশ দেই যাতে করে তারা পাপে উন ্ নতি লাভ করতে পারে । বস ্ তুতঃ তাদের জন ্ য রয়েছে লাঞ ্ ছনাজনক শাস ্ তি ।',\n",
       "       'সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসবে না এবং তারা সাহায ্ যপ ্ রাপ ্ তও হবে না ।',\n",
       "       'একটা দুঃসংবাদ দিবো।',\n",
       "       \"আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লাহ্\\u200cর সন্তান ও তাঁর প্রিয়পাত্র।’’ তুমি বলো -- ''তবে কেন তোমাদের অপরাধের জন্য তিনি তোমাদের শাস্তি দেন? না, যাদের তিনি সৃষ্টি করেছেন তোমরা তাদের মধ্যেকার মানুষ। তিনি যাকে ইচ্ছে করেন পরিত্রাণ করেন এবং যাকে ইচ্ছে করেন শাস্তি দেন।’’ আর আল্লাহ্\\u200cরই মহাকাশমন্ডল ও পৃথিবীর সাম্রাজ্য এবং এই দুইয়ের মধ্যে যা আছে, আর তাঁরই দিকে প্রত্যাবর্তন।\",\n",
       "       'এটা দেখ তো।',\n",
       "       'এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা দিয়েছি । তাদের মধ ্ যে কেউ তো হলো তারা যার সাথে আল ্ লাহ কথা বলেছেন , আর কারও মর ্ যাদা উচ ্ চতর করেছেন এবং আমি মরিয়ম তনয় ঈসাকে প ্ রকৃষ ্ ট মু ’ জেযা দান করেছি এবং তাকে শক ্ তি দান করেছি ‘ রুহূল কুদ ্ দুস ’ অর ্ থৎ জিবরাঈলের মাধ ্ যমে । আর আল ্ লাহ যদি ইচ ্ ছা করতেন , তাহলে পরিস ্ কার নির ্ দেশ এসে যাবার পর পয়গম ্ বরদের পেছনে যারা ছিল তারা লড়াই করতো না । কিন ্ তু তাদের মধ ্ যে মতবিরোধ সৃষ ্ টি হয়ে গেছে । অতঃপর তাদের কেউ তো ঈমান এনেছে , আর কেউ হয়েছে কাফের । আর আল ্ লাহ যদি ইচ ্ ছা করতেন , তাহলে তারা পরস ্ পর লড়াই করতো , কিন ্ তু আল ্ লাহ তাই করেন , যা তিনি ইচ ্ ছা করেন ।',\n",
       "       'দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো দিবারাত ্ রি চক ্ রান ্ ত করে আমাদেরকে নির ্ দেশ দিতে যেন আমরা আল ্ লাহকে না মানি এবং তাঁর অংশীদার সাব ্ যস ্ ত করি তারা যখন শাস ্ তি দেখবে , তখন মনের অনুতাপ মনেই রাখবে । বস ্ তুতঃ আমি কাফেরদের গলায় বেড়ী পরাব । তারা সে প ্ রতিফলই পেয়ে থাকে যা তারা করত ।',\n",
       "       'রুহিতনের বিবি', 'এখন বাইরে চলো, চলো, যাই', 'যথেষ্ট হয়েছে.',\n",
       "       'এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কিছু আছে তা নিশ ্ চয়ই আল ্ লাহ ্ \\u200c র ? তিনি অবশ ্ য জানেন তোমরা যা-কিছুতে রয়েছ । আর যেদিন তাদের তাঁর কাছে ফেরত নেওয়া হবে সেদিন তাদের জানিয়ে দেওয়া হবে যা তারা করত । আর আল ্ লাহ ্ সব- কিছু সন ্ বন ্ ধে সর ্ বজ ্ ঞাতা ।',\n",
       "       'শুভ রাত্রি, জনাব ।',\n",
       "       'তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হয়ে গেছে ।',\n",
       "       'সিরিলিক/ইউক্রেনীয়', 'KDE বিভাজন ব্যবস্থাপক', 'সবচেয়ে ভাল',\n",
       "       'আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জলভাষী । অতএব , তাকে আমার সাথে সাহায ্ যের জন ্ যে প ্ রেরণ করুন । সে আমাকে সমর ্ থন জানাবে । আমি আশংকা করি যে , তারা আমাকে মিথ ্ যাবাদী বলবে ।',\n",
       "       'না !', 'ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ',\n",
       "       '%s: groupid মান %d করা যায়নি', 'ঘন্টা',\n",
       "       'কাফেররা কি এখন অপেক ্ ষা করছে যে , তাদের কাছে ফেরেশতারা আসবে কিংবা আপনার পালনকর ্ তার নির ্ দেশ পৌছবে ? তাদের পূর ্ ববর ্ তীরা এমনই করেছিল । আল ্ লাহ তাদের প ্ রতি অবিচার করেননি ; কিন ্ তু তারা স ্ বয়ং নিজেদের প ্ রতি জুলুম করেছিল ।',\n",
       "       'আমার... ...স্বামী.',\n",
       "       'আপনার ওয়েবক্যামে ছবি এবং ভিডিও নিন, আনন্দিত গ্রাফিকেল আবহ সহযোগে',\n",
       "       'MD5 ফিঙ্গারপ্রিন্ট', 'ডিস্ক অনুলিপি (_c)', 'আপনি একা?',\n",
       "       'আর তোমরা নিশ ্ চয়ই আমাদের কাছে এসেছ একে একে যেমন তোমাদের আমরা প ্ রথমবার সৃষ ্ টি করেছিলাম , আর যা তোমাদের দিয়েছিলাম তা তোমরা তোমাদের পিঠের পেছনে ফেলে এসেছ , আর তোমাদের সঙ ্ গে তোমাদের সুপারিশকারীদের দেখছি না যাদের তোমরা দাবি করতে যে তারা তোমাদের মধ ্ যে নিশ ্ চিত অংশীদার । নিশ ্ চয় তোমাদের মধ ্ যেকার বন ্ ধন ছিন ্ ন হয়েছে আর তোমাদের থেকে উধাও হয়েছে যা তোমরা দাবি করতে ।',\n",
       "       'রহমান , রহীম ।', 'এটা আমার প্যান ছিলনা\\u200e.',\n",
       "       'ক্লায়েন্ট সংক্রান্ত অপশন প্রদর্শন করা হবে',\n",
       "       'আমি সফল হতে পারার আগেই আমাকে ওরা ধরে নিয়ে গেল', '-আপনি কে?',\n",
       "       'PKCS #1 MD2 RSA এনক্রিপশনসহ',\n",
       "       'হাই পয়েন্টCity name (optional, probably does not need a translation)',\n",
       "       'প্রাপকদের তথ্য ব্যবহার করে অনুসন্ধান ফোল্ডার নির্মাণ করুন...(_t)',\n",
       "       'কিন ্ ত তাদের তো এদের উপরে তত ্ ত ্ বাবধায়ক করে পাঠানো হয় নি ।',\n",
       "       'প্রতিবার Evolution আরম্ভ করার সময় পরীক্ষা করা হবে এটি ডিফল্ট মেইলার হিসাবে চিহ্নিত কিনা।',\n",
       "       'l', 'বুধবার', 'অ্যারিজোনা.',\n",
       "       '%s: %s সিগন্যাল হ্যান্ডলার স্থাপনে সমস্যা হয়েছে: %s',\n",
       "       'না, না, না.',\n",
       "       'আপনি কি এই অ্যাকাউন্ট ও এর সাথে যুক্ত সমস্ত প্রক্সি মুছে ফেলতে চান?',\n",
       "       'যাতে তোমরা তাদের পিঠের উপর আরোহণ কর । অতঃপর তোমাদের পালনকর ্ তার নেয়ামত স ্ মরণ কর এবং বল পবিত ্ র তিনি , যিনি এদেরকে আমাদের বশীভূত করে দিয়েছেন এবং আমরা এদেরকে বশীভূত করতে সক ্ ষম ছিলাম না ।',\n",
       "       'আবার... ...', 'চিড়িতনের টেক্কা',\n",
       "       \"লোকেরা কি মনে করে যে তাদের ছেড়ে দেওয়া হবে যদি তারা বলে -- ''আমরা ঈমান এনেছি’’, আর তাদের পরীক্ষা করা হবে না?\",\n",
       "       'চিন্তা কোরনা.', 'কেন তুমি তোমার মন পাল্টালে?'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100:150, ['bn', 'en']].values[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b3bb6",
   "metadata": {},
   "source": [
    "## Train a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203c3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb1f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_tokenizer(file_path:str, output_path:str, vocab_size:int, lang:str = Literal['bn', 'en']):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\"File Path Does Not Exist\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna()\n",
    "    training_data = df.loc[:, lang].values\n",
    "    \n",
    "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(vocab_size=vocab_size,\n",
    "                               min_frequency=2,\n",
    "                               special_tokens=[\"[UNK]\", \"[PAD]\", \"[EOS]\", \"[SOS]\"])\n",
    "    \n",
    "    tokenizer.train_from_iterator(training_data, trainer)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    tokenizer.save(f\"./{output_path}/{lang}_tokenizer.json\")\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626e5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/arafat/projects/deeplearning_crash_course/data/bangla_english_translation.csv'\n",
    "en_tokenizer = train_and_save_tokenizer(path, 'Tokenizer', 1000, 'en')\n",
    "bn_tokenizer = train_and_save_tokenizer(path, 'Tokenizer', 1000, 'bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eecad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([89, 14, 11, 0, 0], ['This', 'is', 'a', '[UNK]', '[UNK]'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_file('/home/arafat/projects/deeplearning_crash_course/Tokenizer/en_tokenizer.json')\n",
    "tokenizer.enable_padding(\n",
    "    pad_id=tokenizer.token_to_id(\"[PAD]\"),\n",
    "    pad_token=\"[PAD]\",\n",
    "    length=None,\n",
    "    # length=50,\n",
    "    direction='right'\n",
    ")\n",
    "\n",
    "sample_text = \"This is a test sentence\"\n",
    "encoding = tokenizer.encode(sample_text)\n",
    "encoding.ids, encoding.tokens\n",
    "\n",
    "# token = torch.stack([encoding[0].ids, encoding[1].ids], padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea990a1a",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a225708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2643fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(batch):\n",
    "    bn_sentences = [item[0] for item in batch]\n",
    "    en_sentences = [item[1] for item in batch]\n",
    "    bn_padded = torch.nn.utils.rnn.pad_sequence(bn_sentences, batch_first=True, padding_value=1)\n",
    "    en_padded = torch.nn.utils.rnn.pad_sequence(en_sentences, batch_first=True, padding_value=1)\n",
    "    return bn_padded, en_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineTranslation(Dataset):\n",
    "    def __init__(self, file_path:str, en_tokenizer_path:str, bn_tokenizer_path:str, split:str='train'):\n",
    "        super().__init__()\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {file_path}\")\n",
    "        if not os.path.exists(en_tokenizer_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {en_tokenizer_path}\")\n",
    "        if not os.path.exists(bn_tokenizer_path):\n",
    "            raise FileNotFoundError(f\"File Path does not exists for {bn_tokenizer_path}\")\n",
    "        assert split in [\"train\", \"validation\"], \"Split must be either 'train' or 'validation'\"\n",
    "                \n",
    "        self.file_path = file_path\n",
    "        self.csv_file = pd.read_csv(file_path)\n",
    "        if split == \"train\":\n",
    "            self.csv_file = self.csv_file.sample(frac=0.8, random_state=42)\n",
    "            \n",
    "        self.en_tokenizer = Tokenizer.from_file(en_tokenizer_path)\n",
    "        self.bn_tokenizer = Tokenizer.from_file(bn_tokenizer_path)\n",
    "        \n",
    "        self.en_tokenizer.enable_padding(\n",
    "            pad_id=self.en_tokenizer.token_to_id(\"[PAD]\"),\n",
    "            pad_token=\"[PAD]\",\n",
    "            length=None,\n",
    "            direction='right'\n",
    "        )\n",
    "        \n",
    "        self.bn_tokenizer.enable_padding(\n",
    "            pad_id=self.bn_tokenizer.token_to_id(\"[PAD]\"),\n",
    "            pad_token=\"[PAD]\",\n",
    "            length=None,\n",
    "            direction='right'\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.csv_file.loc[idx, ['bn', 'en']].values\n",
    "        bangla, english = sentences[0], sentences[1]\n",
    "        bn_encoding = self.bn_tokenizer.encode(bangla)\n",
    "        en_encoding = self.en_tokenizer.encode(english)\n",
    "        return torch.tensor(bn_encoding.ids), torch.tensor(en_encoding.ids)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b9c93e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MachineTranslation(path, './Tokenizer/en_tokenizer.json', './Tokenizer/bn_tokenizer.json')\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ddfd6c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 57]), torch.Size([10, 67]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fa68ff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ছবি জন্য তৈরি করা'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = x[9].tolist()\n",
    "bn_tokenizer.decode(token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "02e4be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bn    হ্যাঁ?\n",
       "en     Yeah?\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/arafat/projects/deeplearning_crash_course/data/bangla_english_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b4fad01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আ...</td>\n",
       "      <td>You must name this Search Folder.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান ক...</td>\n",
       "      <td>Those who disbelieve should not assume that We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসব...</td>\n",
       "      <td>A day on which their scheming will not benefit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>একটা দুঃসংবাদ দিবো।</td>\n",
       "      <td>I've got some bad news.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লা...</td>\n",
       "      <td>No : You are only mortals , of His creation . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>এটা দেখ তো।</td>\n",
       "      <td>Check that out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা ...</td>\n",
       "      <td>And to Jesus , son of Mary , We gave tokens , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো...</td>\n",
       "      <td>Those who were despised say unto those who wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>রুহিতনের বিবি</td>\n",
       "      <td>the queen of diamonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>এখন বাইরে চলো, চলো, যাই</td>\n",
       "      <td>Come on, let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>যথেষ্ট হয়েছে.</td>\n",
       "      <td>That's enough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কি...</td>\n",
       "      <td>He has Knowledge of what state you are upon . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>শুভ রাত্রি, জনাব ।</td>\n",
       "      <td>Good night, sir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হ...</td>\n",
       "      <td>Then go to the Pharaoh as he has become exceed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>সিরিলিক/ইউক্রেনীয়</td>\n",
       "      <td>Cyrillic/Ukrainian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KDE বিভাজন ব্যবস্থাপক</td>\n",
       "      <td>KDE Partition Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>সবচেয়ে ভাল</td>\n",
       "      <td>The best.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জল...</td>\n",
       "      <td>And my brother , Haroun , he is more eloquent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>না !</td>\n",
       "      <td>No!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ</td>\n",
       "      <td>3D artillery game similar to Scorched Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>%s: groupid মান %d করা যায়নি</td>\n",
       "      <td>%s: Couldn't set groupid to %d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    bn  \\\n",
       "100  চিহ্নিত অনুসন্ধানের ফোল্ডারের নাম উল্লেখ করা আ...   \n",
       "101  কাফেররা যেন মনে না করে যে আমি যে , অবকাশ দান ক...   \n",
       "102  সেদিন তাদের চক ্ রান ্ ত তাদের কোন উপকারে আসব...   \n",
       "103                                একটা দুঃসংবাদ দিবো।   \n",
       "104  আর ইহুদী ও খ ্ রীষ ্ টানরা বলে -- ''আমরা আল্লা...   \n",
       "105                                        এটা দেখ তো।   \n",
       "106  এই রসূলগণ-আমি তাদের কাউকে কারো উপর মর ্ যাদা ...   \n",
       "107  দুর ্ বলরা অহংকারীদেরকে বলবে , বরং তোমরাই তো...   \n",
       "108                                      রুহিতনের বিবি   \n",
       "109                            এখন বাইরে চলো, চলো, যাই   \n",
       "110                                      যথেষ্ট হয়েছে.   \n",
       "111  এটি কি নয় যে মহাকাশমন ্ ডলীতে ও পৃথিবীতে যা-কি...   \n",
       "112                                 শুভ রাত্রি, জনাব ।   \n",
       "113  তোমরা উভয়ে ফেরআউনের কাছে যাও সে খুব উদ ্ ধত হ...   \n",
       "114                                  সিরিলিক/ইউক্রেনীয়   \n",
       "115                              KDE বিভাজন ব্যবস্থাপক   \n",
       "116                                         সবচেয়ে ভাল   \n",
       "117  আমার ভাই হারুণ , সে আমা অপেক ্ ষা প ্ রাঞ ্ জল...   \n",
       "118                                               না !   \n",
       "119      ত্রিমাত্রিক আর্টিলারি খেলা অনুরূপ স্কোরচ আর্থ   \n",
       "120                       %s: groupid মান %d করা যায়নি   \n",
       "\n",
       "                                                    en  \n",
       "100                  You must name this Search Folder.  \n",
       "101  Those who disbelieve should not assume that We...  \n",
       "102  A day on which their scheming will not benefit...  \n",
       "103                            I've got some bad news.  \n",
       "104  No : You are only mortals , of His creation . ...  \n",
       "105                                    Check that out.  \n",
       "106  And to Jesus , son of Mary , We gave tokens , ...  \n",
       "107  Those who were despised say unto those who wer...  \n",
       "108                              the queen of diamonds  \n",
       "109                                 Come on, let's go.  \n",
       "110                                     That's enough.  \n",
       "111  He has Knowledge of what state you are upon . ...  \n",
       "112                                   Good night, sir.  \n",
       "113  Then go to the Pharaoh as he has become exceed...  \n",
       "114                                 Cyrillic/Ukrainian  \n",
       "115                              KDE Partition Manager  \n",
       "116                                          The best.  \n",
       "117  And my brother , Haroun , he is more eloquent ...  \n",
       "118                                                No!  \n",
       "119        3D artillery game similar to Scorched Earth  \n",
       "120                     %s: Couldn't set groupid to %d  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100:120, ['bn', 'en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a006a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 1) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m x = torch.tensor(\u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m y = torch.tensor([\u001b[32m2\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m4\u001b[39m,\u001b[32m5\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: zero-dimensional tensor (at position 1) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1)\n",
    "y = torch.tensor([2,3,4,5])\n",
    "torch.cat([y, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969c321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820177f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.zeros(10, 10)\n",
    "mask[:x.shape[0], :x.shape[1]] = 1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f1834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7036, 0.4407, 0.7141, 0.2086, 0.4266],\n",
       "        [0.8826, 0.2820, 0.4906, 0.6313, 0.6343],\n",
       "        [0.2236, 0.9251, 0.9680, 0.4137, 0.7161],\n",
       "        [0.2739, 0.2671, 0.5580, 0.2215, 0.4544],\n",
       "        [0.6278, 0.4673, 0.2455, 0.0232, 0.7803]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d9c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:/notebook/deeplearning_crash_course/data/bangla_english_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.3)\n",
    "other = data[data.index != sample.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf86ebd",
   "metadata": {},
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd0c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/arafat/projects/deeplearning_crash_course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d995ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4b4d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    data_path = './data/bangla_english_translation.csv'\n",
    "    test_size = 0.2\n",
    "    batch_size = 10\n",
    "    epcohs = 10\n",
    "    lr = 1e-4\n",
    "    src_lang = 'en'\n",
    "    tgt_lang = 'bn'\n",
    "    src_vocab_size = 2000\n",
    "    tgt_vocab_size = 2000\n",
    "    seq_len = 15\n",
    "    d_model = 512\n",
    "    N = 6\n",
    "    h = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90912fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = get_dataloder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59b27ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "684622",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 684622",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dataset.py:49\u001b[39m, in \u001b[36mLanguageTranslation.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     src_text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msrc_lang\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     50\u001b[39m     tgt_text = \u001b[38;5;28mself\u001b[39m.ds.loc[index, \u001b[38;5;28mself\u001b[39m.tgt_lang]\n\u001b[32m     51\u001b[39m     src_encoding = \u001b[38;5;28mself\u001b[39m.src_tokenizer.encode(src_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/pandas/core/indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     key = \u001b[38;5;28mtuple\u001b[39m(com.apply_if_callable(x, \u001b[38;5;28mself\u001b[39m.obj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_tuple(key)\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1187\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/pandas/core/frame.py:4232\u001b[39m, in \u001b[36mDataFrame._get_value\u001b[39m\u001b[34m(self, index, col, takeable)\u001b[39m\n\u001b[32m   4226\u001b[39m engine = \u001b[38;5;28mself\u001b[39m.index._engine\n\u001b[32m   4228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, MultiIndex):\n\u001b[32m   4229\u001b[39m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[32m   4230\u001b[39m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[32m   4231\u001b[39m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4232\u001b[39m     row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m series._values[row]\n\u001b[32m   4235\u001b[39m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[32m   4236\u001b[39m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/deeplearning_crash_course/dl_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 684622"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a686ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./data/bangla_english_translation.csv\")\n",
    "sample = data.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bcfbcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5cc4602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>translation</th>\n",
       "      <th>bn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7791</td>\n",
       "      <td>{'bn': 'উড়ন্ত মানুষ.', 'en': 'Bird men!'}</td>\n",
       "      <td>উড়ন্ত মানুষ.</td>\n",
       "      <td>Bird men!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501511</td>\n",
       "      <td>{'bn': 'এসো কেমন অনুভূতি হচ্ছে?', 'en': 'Come....</td>\n",
       "      <td>এসো কেমন অনুভূতি হচ্ছে?</td>\n",
       "      <td>Come. How does it feel?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466456</td>\n",
       "      <td>{'bn': 'এখানে 24 টা আছে.', 'en': \"There's 24 t...</td>\n",
       "      <td>এখানে 24 টা আছে.</td>\n",
       "      <td>There's 24 there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144330</td>\n",
       "      <td>{'bn': 'কী এমন দেখেছিলেন?', 'en': 'What did yo...</td>\n",
       "      <td>কী এমন দেখেছিলেন?</td>\n",
       "      <td>What did you see?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382244</td>\n",
       "      <td>{'bn': 'আমেরিকা/গুয়াতেমালা', 'en': 'America/Gu...</td>\n",
       "      <td>আমেরিকা/গুয়াতেমালা</td>\n",
       "      <td>America/Guatemala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>789173</td>\n",
       "      <td>{'bn': 'সাইফার? ট্যাংক কোথায়?', 'en': 'Hello, ...</td>\n",
       "      <td>সাইফার? ট্যাংক কোথায়?</td>\n",
       "      <td>Hello, Trinity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>293285</td>\n",
       "      <td>{'bn': 'সাহায্য করতে না পারে দুঃখিত পাসপোর্ট ছ...</td>\n",
       "      <td>সাহায্য করতে না পারে দুঃখিত পাসপোর্ট ছাড়া.</td>\n",
       "      <td>Sorry can't help without passport.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>277924</td>\n",
       "      <td>{'bn': 'যখন তাদেরকে মেঘমালা সদৃশ তরংগ আচ ্ ছাদ...</td>\n",
       "      <td>যখন তাদেরকে মেঘমালা সদৃশ তরংগ আচ ্ ছাদিত করে ন...</td>\n",
       "      <td>When the waves overshadow them like a canopy ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>517315</td>\n",
       "      <td>{'bn': '-মাঝখানে', 'en': '- In the middle.'}</td>\n",
       "      <td>-মাঝখানে</td>\n",
       "      <td>- In the middle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>897436</td>\n",
       "      <td>{'bn': 'তাই না?', 'en': \"You understand I can'...</td>\n",
       "      <td>তাই না?</td>\n",
       "      <td>You understand I can't say anything, right?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  ...                                                 en\n",
       "0         7791  ...                                          Bird men!\n",
       "1       501511  ...                            Come. How does it feel?\n",
       "2       466456  ...                                  There's 24 there.\n",
       "3       144330  ...                                  What did you see?\n",
       "4       382244  ...                                  America/Guatemala\n",
       "...        ...  ...                                                ...\n",
       "199995  789173  ...                                    Hello, Trinity.\n",
       "199996  293285  ...                 Sorry can't help without passport.\n",
       "199997  277924  ...  When the waves overshadow them like a canopy ,...\n",
       "199998  517315  ...                                   - In the middle.\n",
       "199999  897436  ...        You understand I can't say anything, right?\n",
       "\n",
       "[200000 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b9151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
